{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDS/ACM/CS 158: Fundamentals of Statistical Learning\n",
    "### PS4, Problem 3: Logistic Regression Analysis of the Stock Market Data\n",
    "> Name: Li, Michael\n",
    " \n",
    "> Email address: mlli@caltech.edu\n",
    "\n",
    "Notes:\n",
    "Please use python 3.6\n",
    "\n",
    "You are required to properly comment and organize your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Helper functions (add/remove part label according to the specific question requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "def logit(x, beta):\n",
    "    \"\"\"\n",
    "    x - a random point p dimensional vector\n",
    "    beta - an estimate for beta\n",
    "    \n",
    "    returns the logistic function for x using beta\n",
    "    \"\"\"\n",
    "    return np.exp(np.matmul(x.transpose(), beta)) / (1 + np.exp(np.matmul(x.transpose(), beta)))\n",
    "\n",
    "def predict(data, beta):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    beta - coefficient estimates for logistic regression\n",
    "    \n",
    "    returns the probabilities of class 1 for each data point\n",
    "    \"\"\"\n",
    "    x = data[:,:-1]\n",
    "    bias = np.matlib.repmat(1, len(x), 1)\n",
    "    x = np.concatenate((bias, x), axis=1)\n",
    "    \n",
    "    return np.apply_along_axis(logit, 1, x, beta)\n",
    "    \n",
    "def logistic_regression(data):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    \n",
    "    returns the coefficient estimates for logistic regression using IRLS\n",
    "    \"\"\"\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    bias = np.matlib.repmat(1, len(x), 1)\n",
    "    x = np.concatenate((bias, x), axis=1)\n",
    "    \n",
    "    # encode the data\n",
    "    y = np.array([0 if item == -1 else item for item in y])\n",
    "    tol = .000001\n",
    "    \n",
    "    # initialize beta to 0\n",
    "    beta = np.array([0]*len(x[0]))\n",
    "    w_k = None\n",
    "    iters = 1 # just to prevent divide by 0 warning\n",
    "    \n",
    "    while True:\n",
    "        p_k = np.apply_along_axis(logit, 1, x, beta)\n",
    "        p_k_minus = 1 - p_k\n",
    "        w_k = np.diag(np.multiply(p_k, p_k_minus))\n",
    "        diff = y - p_k\n",
    "        \n",
    "        intermediate = np.matmul(np.matmul(x.transpose(), w_k), x)\n",
    "        inverse_intermediate = np.linalg.inv(intermediate)\n",
    "        pseudo_x = np.matmul(inverse_intermediate, x.transpose())\n",
    "        beta_next = beta + np.matmul(pseudo_x, diff)\n",
    "        \n",
    "        # stopping condition if our two betas do not change enough\n",
    "        if iters != 1 and np.linalg.norm(beta-beta_next, 2) / np.linalg.norm(beta, 2) < tol:\n",
    "            break\n",
    "        else:\n",
    "            beta = beta_next\n",
    "            iters += 1\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def sigma_squared(x, beta, j):\n",
    "    \"\"\"\n",
    "    x - a matrix where each row corresponds to the \n",
    "        p predictors\n",
    "    beta - the coefficient estimates for logistic regression\n",
    "    j - index of predictor\n",
    "    \n",
    "    returns the sigma_squared diagnol element\n",
    "    \"\"\"\n",
    "    bias = np.matlib.repmat(1, len(x), 1)\n",
    "    x = np.concatenate((bias, x), axis=1)\n",
    "    \n",
    "    p_k = np.apply_along_axis(logit, 1, x, beta)\n",
    "    p_k_minus = 1 - p_k\n",
    "    w_k = np.diag(np.multiply(p_k, p_k_minus))\n",
    "    \n",
    "    return np.linalg.inv(np.matmul(np.matmul(x.transpose(), w_k), x))[j][j]\n",
    "\n",
    "def reduce_data(data, indices):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    indices - which indices to use from the data\n",
    "    \n",
    "    returns the reduced dataset containing only the predictors in indices\n",
    "    \"\"\"\n",
    "    return np.append(data[:,indices], data[:,-1][...,None], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Part A</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('stock_market_train.csv', delimiter=',', skip_header=1)\n",
    "test_data = np.genfromtxt('stock_market_test.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4957056982540905,\n",
       " -1.2949980620766537,\n",
       " -1.3221554529148911,\n",
       " -0.1532395033236583,\n",
       " 0.2928063364320254,\n",
       " 1.0797555989798535,\n",
       " 0.7440645920961294]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_data[:,:-1]\n",
    "y = train_data[:,-1]\n",
    "\n",
    "beta = logistic_regression(train_data)\n",
    "z_scores = []\n",
    "\n",
    "# calculate z_scores for each predictor\n",
    "for i in range(len(beta)):\n",
    "    b = beta.copy()\n",
    "    b[i] = 0\n",
    "    \n",
    "    sig = np.sqrt(sigma_squared(x, b, i))\n",
    "    z_scores.append(beta[i] / sig)\n",
    "\n",
    "z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6201020661861175,\n",
       " 0.19532089800477326,\n",
       " 0.18611639147942072,\n",
       " 0.8782094063929503,\n",
       " 0.7696701846565389,\n",
       " 0.2802510280256544,\n",
       " 0.45683739909704013]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_vals = []\n",
    "\n",
    "# calculate p_vals using z_scores\n",
    "for score in z_scores:\n",
    "    p_vals.append(2*scipy.stats.norm.cdf(-1*np.abs(score)))\n",
    "    \n",
    "p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS estimate</th>\n",
       "      <th>z-score</th>\n",
       "      <th>p val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.135275</td>\n",
       "      <td>-0.495706</td>\n",
       "      <td>0.620102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>-0.073533</td>\n",
       "      <td>-1.294998</td>\n",
       "      <td>0.195321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>-0.072720</td>\n",
       "      <td>-1.322155</td>\n",
       "      <td>0.186116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>-0.008628</td>\n",
       "      <td>-0.153240</td>\n",
       "      <td>0.878209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.292806</td>\n",
       "      <td>0.769670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.057834</td>\n",
       "      <td>1.079756</td>\n",
       "      <td>0.280251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.132874</td>\n",
       "      <td>0.744065</td>\n",
       "      <td>0.456837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OLS estimate   z-score     p val\n",
       "1          -0.135275 -0.495706  0.620102\n",
       "Lag1       -0.073533 -1.294998  0.195321\n",
       "Lag2       -0.072720 -1.322155  0.186116\n",
       "Lag3       -0.008628 -0.153240  0.878209\n",
       "Lag4        0.016658  0.292806  0.769670\n",
       "Lag5        0.057834  1.079756  0.280251\n",
       "Volume      0.132874  0.744065  0.456837"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ['1', 'Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']\n",
    "pd.DataFrame(data={'OLS estimate': beta, \n",
    "                   'z-score': z_scores, \n",
    "                   'p val': p_vals},\n",
    "             index=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.496"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = predict(test_data, beta)\n",
    "test_preds = [1 if item >= .5 else -1 for item in test_preds]\n",
    "average_err = sum(test_preds != test_data[:,-1]) / len(test_preds)\n",
    "average_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Part B</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_significant_indexes = [0, 1]\n",
    "train_data = reduce_data(train_data, most_significant_indexes)\n",
    "new_beta = logistic_regression(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.472"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = reduce_data(test_data, most_significant_indexes)\n",
    "test_preds = predict(test_data, new_beta)\n",
    "test_preds = [1 if item >= .5 else -1 for item in test_preds]\n",
    "average_err = sum(test_preds != test_data[:,-1]) / len(test_preds)\n",
    "average_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find test errors for g_0 and g_1\n",
    "n_10 = 0\n",
    "n_11 = 0\n",
    "n_00 = 0\n",
    "n_01 = 0\n",
    "\n",
    "for i in range(len(test_preds)):\n",
    "    if test_data[:,-1][i] == 1:\n",
    "        if test_preds[i] == 1:\n",
    "            n_00 += 1\n",
    "        else:\n",
    "            n_10 += 1\n",
    "    else:\n",
    "        if test_preds[i] == 1:\n",
    "            n_01 += 1\n",
    "        else:\n",
    "            n_11 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4603174603174603, 0.5081967213114754)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_0_test_err = n_01 / (n_00 + n_01)\n",
    "g_1_test_err = n_10 / (n_11 + n_10)\n",
    "g_0_test_err, g_1_test_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these errors we see that the model is wrong 46% of the time when it predicts the market will go up and 51% of the time when it predicts the market will go down. From this, we know the model is as good as guessing thus I would avoid trades using this model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
