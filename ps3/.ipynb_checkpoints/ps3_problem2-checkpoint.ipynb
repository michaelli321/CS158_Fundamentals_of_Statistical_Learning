{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDS/ACM/CS 158: Fundamentals of Statistical Learning\n",
    "### PS3, Problem 2: Leave-One-Out Cross Validation For Model Selection\n",
    "> Name: Li, Michael\n",
    " \n",
    "> Email address: mlli@caltech.edu\n",
    "\n",
    "Notes:\n",
    "Please use python 3.6\n",
    "\n",
    "You are required to properly comment and organize your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Helper functions (add/remove part label according to the specific question requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.matlib\n",
    "\n",
    "def find_beta(data):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    \n",
    "    returns the OLS estimate of the regression parameter\n",
    "    \"\"\"\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "\n",
    "    # add bias term to training data\n",
    "    bias = np.matlib.repmat(1, len(x), 1)\n",
    "    x = np.concatenate((bias, x), axis=1)\n",
    "\n",
    "    # calculate beta\n",
    "    intermediate = np.matmul(x.transpose(), x)\n",
    "    inverse_intermediate = np.linalg.inv(np.array(intermediate))\n",
    "    pseudo_x = np.matmul(inverse_intermediate, x.transpose())\n",
    "\n",
    "    return np.matmul(pseudo_x, y), np.matmul(x, pseudo_x)\n",
    "\n",
    "def predict(ols, data):\n",
    "    \"\"\"\n",
    "    ols - ols estimate of the regression parameter\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "           \n",
    "    returns the predictions for the observations in data\n",
    "    \"\"\"\n",
    "\n",
    "    x_with_bias_term = np.insert(data[:-1], 0, 1)\n",
    "    return np.matmul(x_with_bias_term, ols)\n",
    "\n",
    "def leave_one_out_cv(data):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "           \n",
    "    returns the leave one out cross validation of the data\n",
    "    \"\"\"\n",
    "    ols, hat = find_beta(data)\n",
    "    return np.mean([((data[i][-1] - predict(ols, data[i])) / (1-hat[i][i]))**2 for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat data so we have 3 models\n",
    "f_1_data = np.genfromtxt('dataset5.csv', delimiter=',',skip_header =1)\n",
    "f_2_data = np.array([[f_1_data[i][0], np.sin(f_1_data[i][1]), f_1_data[i][2]] for i in range(len(f_1_data))])\n",
    "f_3_data = np.delete(f_1_data, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the leave one out cross validation for each dataset\n",
    "f_1_err = leave_one_out_cv(f_1_data)\n",
    "f_2_err = leave_one_out_cv(f_2_data)\n",
    "f_3_err = leave_one_out_cv(f_3_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Leave One Out Cross Validation for Model 1 is 1.1074945247730847\n",
      "The Leave One Out Cross Validation for Model 2 is 1.0802973038999084\n",
      "The Leave One Out Cross Validation for Model 3 is 1.500086491089816\n"
     ]
    }
   ],
   "source": [
    "print(\"The Leave One Out Cross Validation for Model 1 is {}\".format(f_1_err))\n",
    "print(\"The Leave One Out Cross Validation for Model 2 is {}\".format(f_2_err))\n",
    "print(\"The Leave One Out Cross Validation for Model 3 is {}\".format(f_3_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the leave one out cross validations, it looks like model 2 has the lowest estimated test error. Thus, I would definitively select model $f_2$(X) as the best model using this metric since each model was trained and tested on the same data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
