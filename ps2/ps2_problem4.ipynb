{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IDS/ACM/CS 158: Fundamentals of Statistical Learning\n",
    "### PS2, Problem 4:  Linear Regression Analysis of the Prostate Cancer Data\n",
    "> Name: Li, Michael\n",
    " \n",
    "> Email address: mlli@caltech.edu\n",
    "\n",
    "Notes:\n",
    "Please use python 3.6\n",
    "\n",
    "You are required to properly comment and organize your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Helper functions (add/remove part label according to the specific question requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_col(column):\n",
    "    \"\"\"\n",
    "    column - an np array of values from a population\n",
    "    \n",
    "    returns the standardized column with mean 0 and std = 1\n",
    "    \"\"\"\n",
    "    mean = np.mean(column)\n",
    "    std = np.std(column)\n",
    "        \n",
    "    return (column - mean) / std\n",
    "\n",
    "def find_beta(data):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    \n",
    "    returns the OLS estimate of the regression parameter\n",
    "    \"\"\"\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "\n",
    "    # add bias term to training data\n",
    "    bias = np.matlib.repmat(1, len(x), 1)\n",
    "    x = np.concatenate((bias, x), axis=1)\n",
    "\n",
    "    # calculate beta\n",
    "    intermediate = np.matmul(x.transpose(), x)\n",
    "    inverse_intermediate = np.linalg.inv(np.array(intermediate))\n",
    "    pseudo_x = np.matmul(inverse_intermediate, x.transpose())\n",
    "\n",
    "    return np.matmul(pseudo_x, y), inverse_intermediate\n",
    "\n",
    "def predict(ols, data):\n",
    "    \"\"\"\n",
    "    ols - ols estimate of the regression parameter\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "           \n",
    "    returns the predictions for the observations in data\n",
    "    \"\"\"\n",
    "    x_with_bias_term = np.concatenate((np.matlib.repmat(1, len(data), 1), data[:,:-1]), axis=1)\n",
    "    return np.matmul(x_with_bias_term, ols)\n",
    "\n",
    "def rss(data, preds):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    preds - the predictions for the observations in data\n",
    "    \n",
    "    returns the residual sum of squares for the values\n",
    "    \"\"\"\n",
    "    return np.sum((data[:,-1] - preds)**2)\n",
    "\n",
    "def find_sigma(data, preds):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    preds - the predictions for the observations in data\n",
    "    \n",
    "    returns sigma hat for the values\n",
    "    \"\"\"\n",
    "    coef = 1 / (len(data) - len(data[0]))\n",
    "    tot = rss(data, preds)\n",
    "    return np.sqrt(coef * tot)\n",
    "\n",
    "def l2_loss(data, preds):\n",
    "    \"\"\"\n",
    "    data - a matrix where each row corresponds to the \n",
    "           p predictors in the first p columns and\n",
    "           the observed output y in the final column\n",
    "    preds - the predictions for the observations in data\n",
    "    \n",
    "    returns the L2 loss of the values\n",
    "    \"\"\"\n",
    "    return np.mean((data[:,-1] - preds)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Part A</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('prostate_cancer.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "standardized_data = data.copy()\n",
    "\n",
    "for i in range(len(data[0])-2):\n",
    "    standardized_data[:,i] = standardize_col(data[:,i])\n",
    "\n",
    "# split the data into train and test\n",
    "train_data = np.array([observation[:-1] for observation in standardized_data if observation[-1] == 1])\n",
    "test_data = np.array([observation[:-1] for observation in standardized_data if observation[-1] == 0])\n",
    "\n",
    "# find the OLS estimate and keep track of the inverse for calculations later\n",
    "ols_full_model, full_model_inverse_intermediate = find_beta(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.46493292,  0.67601634,  0.26169361, -0.14073374,  0.20906052,\n",
       "        0.30362332, -0.28700184, -0.02119493,  0.26557614])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Part B</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_training_preds = predict(ols_full_model, train_data)\n",
    "full_model_sigma = find_sigma(train_data, full_model_training_preds)\n",
    "\n",
    "# All the values of this part are summarized at bottom of the file in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = []\n",
    "\n",
    "for i in range(len(ols_full_model)):\n",
    "    z_scores.append(ols_full_model[i] / (full_model_sigma * np.sqrt(full_model_inverse_intermediate[i][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27.598203120218404,\n",
       " 5.366290456150523,\n",
       " 2.7507893898693854,\n",
       " -1.3959089818189607,\n",
       " 2.055845625930907,\n",
       " 2.4692551777938245,\n",
       " -1.8669126353948005,\n",
       " -0.14668120644372185,\n",
       " 1.737839719569918]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wald_test = []\n",
    "\n",
    "for i in range(len(ols_full_model)):\n",
    "    wald_test.append(2*scipy.stats.norm.cdf(-1 * np.abs(z_scores[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1693547957255616e-167,\n",
       " 8.037247566881759e-08,\n",
       " 0.005945185311053233,\n",
       " 0.16274190557571133,\n",
       " 0.039797398582855026,\n",
       " 0.013539463005511015,\n",
       " 0.06191378907134302,\n",
       " 0.8833836532246512,\n",
       " 0.08223905974843178]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wald_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = []\n",
    "\n",
    "for i in range(len(ols_full_model)):\n",
    "    t_test.append(2*scipy.stats.t(len(train_data) - len(train_data[0])).cdf(-1 * np.abs(z_scores[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.761696772938845e-35,\n",
       " 1.4694149583757016e-06,\n",
       " 0.007917894909336934,\n",
       " 0.16806259017049052,\n",
       " 0.044307842021366985,\n",
       " 0.01650538687470883,\n",
       " 0.06697084708906915,\n",
       " 0.8838923143371643,\n",
       " 0.0875462787480178]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_intervals = []\n",
    "\n",
    "for i in range(len(ols_full_model)):\n",
    "    factor = 2 * full_model_sigma * np.sqrt(full_model_inverse_intermediate[i][i])\n",
    "    interval = [round(ols_full_model[i]-factor, 2), round(ols_full_model[i]+factor, 2)]\n",
    "    confidence_intervals.append(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.29, 2.64],\n",
       " [0.42, 0.93],\n",
       " [0.07, 0.45],\n",
       " [-0.34, 0.06],\n",
       " [0.01, 0.41],\n",
       " [0.06, 0.55],\n",
       " [-0.59, 0.02],\n",
       " [-0.31, 0.27],\n",
       " [-0.04, 0.57]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Part C</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the indexes of the coefficients that are insignificant\n",
    "insignificant_coefficients = (np.where(np.abs(z_scores) < 2)[0] & np.where(np.array(wald_test) > .05)[0]) - 1\n",
    "\n",
    "# reduce the dataset and find new OLS estimate and predictions\n",
    "reduced_train_data = np.delete(train_data, insignificant_coefficients, 1)\n",
    "reduced_test_data = np.delete(test_data, insignificant_coefficients, 1)\n",
    "ols_reduced, _ = find_beta(reduced_train_data)\n",
    "reduced_training_preds = predict(ols_reduced, reduced_train_data)\n",
    "\n",
    "# calculate rss for both models\n",
    "rss_h0 = rss(reduced_train_data, reduced_training_preds)\n",
    "rss_h1 = rss(train_data, full_model_training_preds)\n",
    "p = len(train_data[0])\n",
    "p_reduced = len(reduced_train_data[0])\n",
    "\n",
    "# calculate f and then find p value\n",
    "f = ((rss_h0 - rss_h1) / (p - p_reduced)) / (rss_h1 / (len(train_data)- p))\n",
    "f_test_p_val = 1 - scipy.stats.f(p-p_reduced, (len(train_data)- p)).cdf(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16933707265225229"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test_p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Part D</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Average Test Error: 1.0567332280603818\n",
      "Full Model Average Test Error: 0.5212740055076003\n",
      "Reduced Model Average Test Error: 0.45633212204016255\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "b0 = np.mean(train_data[:,-1])\n",
    "base_err = l2_loss(test_data, b0)\n",
    "\n",
    "# full model\n",
    "full_model_testing_preds = predict(ols_full_model, test_data)\n",
    "full_err = l2_loss(test_data, full_model_testing_preds)\n",
    "\n",
    "# reduced model\n",
    "reduced_test_preds = predict(ols_reduced, reduced_test_data)\n",
    "reduced_err = l2_loss(test_data, reduced_test_preds)\n",
    "\n",
    "print(\"Base Model Average Test Error: {}\".format(base_err))\n",
    "print(\"Full Model Average Test Error: {}\".format(full_err))\n",
    "print(\"Reduced Model Average Test Error: {}\".format(reduced_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS estimate</th>\n",
       "      <th>z-score</th>\n",
       "      <th>wald test p val</th>\n",
       "      <th>t test p val</th>\n",
       "      <th>95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.464933</td>\n",
       "      <td>27.598203</td>\n",
       "      <td>1.169355e-167</td>\n",
       "      <td>4.761697e-35</td>\n",
       "      <td>[2.29, 2.64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>0.676016</td>\n",
       "      <td>5.366290</td>\n",
       "      <td>8.037248e-08</td>\n",
       "      <td>1.469415e-06</td>\n",
       "      <td>[0.42, 0.93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.261694</td>\n",
       "      <td>2.750789</td>\n",
       "      <td>5.945185e-03</td>\n",
       "      <td>7.917895e-03</td>\n",
       "      <td>[0.07, 0.45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.140734</td>\n",
       "      <td>-1.395909</td>\n",
       "      <td>1.627419e-01</td>\n",
       "      <td>1.680626e-01</td>\n",
       "      <td>[-0.34, 0.06]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.209061</td>\n",
       "      <td>2.055846</td>\n",
       "      <td>3.979740e-02</td>\n",
       "      <td>4.430784e-02</td>\n",
       "      <td>[0.01, 0.41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.303623</td>\n",
       "      <td>2.469255</td>\n",
       "      <td>1.353946e-02</td>\n",
       "      <td>1.650539e-02</td>\n",
       "      <td>[0.06, 0.55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>-0.287002</td>\n",
       "      <td>-1.866913</td>\n",
       "      <td>6.191379e-02</td>\n",
       "      <td>6.697085e-02</td>\n",
       "      <td>[-0.59, 0.02]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>-0.021195</td>\n",
       "      <td>-0.146681</td>\n",
       "      <td>8.833837e-01</td>\n",
       "      <td>8.838923e-01</td>\n",
       "      <td>[-0.31, 0.27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.265576</td>\n",
       "      <td>1.737840</td>\n",
       "      <td>8.223906e-02</td>\n",
       "      <td>8.754628e-02</td>\n",
       "      <td>[-0.04, 0.57]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         OLS estimate    z-score  wald test p val  t test p val         95% CI\n",
       "1            2.464933  27.598203    1.169355e-167  4.761697e-35   [2.29, 2.64]\n",
       "lcavol       0.676016   5.366290     8.037248e-08  1.469415e-06   [0.42, 0.93]\n",
       "lweight      0.261694   2.750789     5.945185e-03  7.917895e-03   [0.07, 0.45]\n",
       "age         -0.140734  -1.395909     1.627419e-01  1.680626e-01  [-0.34, 0.06]\n",
       "lbph         0.209061   2.055846     3.979740e-02  4.430784e-02   [0.01, 0.41]\n",
       "svi          0.303623   2.469255     1.353946e-02  1.650539e-02   [0.06, 0.55]\n",
       "lcp         -0.287002  -1.866913     6.191379e-02  6.697085e-02  [-0.59, 0.02]\n",
       "gleason     -0.021195  -0.146681     8.833837e-01  8.838923e-01  [-0.31, 0.27]\n",
       "pgg45        0.265576   1.737840     8.223906e-02  8.754628e-02  [-0.04, 0.57]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ['1', 'lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']\n",
    "pd.DataFrame(data={'OLS estimate': ols_full_model, \n",
    "                   'z-score': z_scores, \n",
    "                   'wald test p val': wald_test, \n",
    "                   't test p val': t_test, \n",
    "                   '95% CI': confidence_intervals}, \n",
    "             index=['1', 'lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
